{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEN 6885 Reinforcement Learning coding assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should remain in the block marked by<br />\n",
    "\\############################<br />\n",
    "\\# YOUR CODE STARTS HERE<br />\n",
    "\\# YOUR CODE ENDS HERE<br />\n",
    "\\############################<br />\n",
    "Please don't edit anything outside the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Incremental Implementation of Average\n",
    "We've finished the incremental implementation of average for you. Please call the function estimate with 1/step step size and fixed step size to compare the difference between this two on a simulated Bandit problem.<br />\n",
    "<span style=\"color:red\">(2 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLalgs is a package containing Reinforcement Learning algorithms Epsilon-Greedy, Policy Iteration, Value Iteration, Q-Learning, and SARSA.\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.utils import estimate\n",
    "random.seed(6885)\n",
    "numTimeStep = 10000\n",
    "q_h = np.zeros(numTimeStep + 1) # Q Value estimate with 1/step step size\n",
    "q_f = np.zeros(numTimeStep + 1) # Q value estimate with fixed step size\n",
    "FixedStepSize = 0.5 #A large number to exaggerate the difference\n",
    "for step in range(1, numTimeStep + 1):\n",
    "    if step < numTimeStep / 2:\n",
    "        r = random.gauss(mu = 1, sigma = 0.1)\n",
    "    else:\n",
    "        r = random.gauss(mu = 3, sigma = 0.1)\n",
    "    \n",
    "    #TIPS: Call function estimate defined in ./RLalgs/utils.py\n",
    "    ############################\n",
    "    # YOUR CODE STARTS HERE\n",
    "    q_h[step] = estimate(q_h[step-1],1/step,r)\n",
    "    q_f[step] = estimate(q_f[step-1],FixedStepSize,r)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    ############################\n",
    "    \n",
    "q_h = q_h[1:]\n",
    "q_f = q_f[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the two Q value estimates. (Please include a title, labels on both axes, and legends)<br />\n",
    "<span style=\"color:red\">(3 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Q value estimate - 1/step vs fixed step size')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "plt.plot(q_h)\n",
    "plt.plot(q_f)\n",
    "plt.legend(['q_h','q_f'])\n",
    "plt.ylabel('estimate')\n",
    "plt.xlabel('step')\n",
    "plt.title('Q value estimate - 1/step vs fixed step size')\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $\\epsilon$-Greedy for Exploration\n",
    "In Reinforcement Learning, we are always faced with the dilemma of exploration and exploitation. $\\epsilon$-Greedy is a trade-off between them. You are gonna implement Greedy and $\\epsilon$-Greedy. We combine these two policies in one function by treating Greedy as $\\epsilon$-Greedy where $\\epsilon = 0$. Edit the function epsilon_greedy in ./RLalgs/utils.py.<br />\n",
    "<span style=\"color:red\">(5 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values:\n",
      "[ 0.61264537  0.27923079 -0.84600857  0.05469574 -1.09990968]\n",
      "Greedy Choice = [0]\n",
      "Epsilon-Greedy Choice = [0]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.utils import epsilon_greedy\n",
    "np.random.seed(6885) #Set the seed to cancel the randomness\n",
    "q = np.random.normal(0, 1, size = 5)\n",
    "\n",
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "greedy_action = epsilon_greedy(q,0,6885) #Use epsilon = 0 for Greedy\n",
    "e_greedy_action = epsilon_greedy(q,0.1,6885) #Use epsilon = 0.1\n",
    "# YOUR CODE ENDS HERE\n",
    "############################\n",
    "print('Values:')\n",
    "print(q)\n",
    "print('Greedy Choice =', greedy_action)\n",
    "print('Epsilon-Greedy Choice =', e_greedy_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results.<br />\n",
    "Values:<br />\n",
    "\\[ 0.61264537  0.27923079 -0.84600857  0.05469574 -1.09990968\\]<br />\n",
    "Greedy Choice = 0<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frozen Lake Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Derive Q value from V value\n",
    "Edit function action_evaluation in ./RLalgs/utils.py.<br />\n",
    "TIPS: $q(s, a)=\\sum_{s',r}p(s',r|s,a)(r+\\gamma v(s'))$<br />\n",
    "<span style=\"color:red\">(5 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values:\n",
      "[[1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.33333333 1.33333333 1.33333333]\n",
      " [1.         1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.utils import action_evaluation\n",
    "v = np.ones(16)\n",
    "q = action_evaluation(env = env.env, gamma = 1, v = v)\n",
    "print('Action values:')\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get Q values all equal to one except at State 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-codes of the following four algorithms can be found on Page 80, 83, 130, 131 of the Sutton's book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model-based RL algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLalgs.utils import action_evaluation, action_selection, render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Policy Iteration\n",
    "Edit the function policy_iteration and relevant functions in ./RLalgs/pi.py to implement the Policy Iteration Algorithm.<br />\n",
    "<span style=\"color:red\">(15 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State values:\n",
      "[0.82352901 0.82352887 0.82352877 0.82352872 0.82352903 0.\n",
      " 0.52941147 0.         0.82352909 0.82352917 0.76470567 0.\n",
      " 0.         0.88235277 0.94117638 0.        ]\n",
      "Number of iterations to converge = 3\n",
      "[0 3 3 3 0 0 0 0 3 1 0 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.pi import policy_iteration\n",
    "V, policy, numIterations = policy_iteration(env = env.env, gamma = 1, max_iteration = 500, theta = 1e-7)\n",
    "print('State values:')\n",
    "print(V)\n",
    "print('Number of iterations to converge =', numIterations)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get values close to:<br />\n",
    "State values:<br />\n",
    "\\[0.82352774 0.8235272  0.82352682 0.82352662 0.82352791 0.<br />\n",
    "0.52941063 0.         0.82352817 0.82352851 0.76470509 0.<br />0.         0.88235232 0.94117615 0.\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run the following to evaluate your result, comment them when you generate the pdf\n",
    "#Q = action_evaluation(env = env.env, gamma = 1, v = V)\n",
    "#policy_estimate = action_selection(Q)\n",
    "#render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Value Iteration\n",
    "Edit the function value_iteration and relevant functions in ./RLalgs/vi.py to implement the Value Iteration Algorithm.<br />\n",
    "<span style=\"color:red\">(10 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State values:\n",
      "[0.82352901 0.82352887 0.82352877 0.82352872 0.82352904 0.\n",
      " 0.52941147 0.         0.82352909 0.82352917 0.76470567 0.\n",
      " 0.         0.88235277 0.94117638 0.        ]\n",
      "Number of iterations to converge = 1\n",
      "[0 3 3 3 0 0 0 0 3 1 0 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.vi import value_iteration\n",
    "V, policy, numIterations = value_iteration(env = env.env, gamma = 1, max_iteration = 500, theta = 1e-7)\n",
    "print('State values:')\n",
    "print(V)\n",
    "print('Number of iterations to converge =', numIterations)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get values close to:<br />\n",
    "State values:<br />\n",
    "\\[0.82352773 0.82352718  0.8235268 0.8235266 0.8235279 0.<br />\n",
    "0.52941062 0.         0.82352816 0.8235285 0.76470509 0.<br />0.         0.88235231 0.94117615 0.\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run the following to evaluate your result, comment them when you generate the pdf\n",
    "#Q = action_evaluation(env = env.env, gamma = 1, v = V)\n",
    "#policy_estimate = action_selection(Q)\n",
    "#render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model free RL algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Q-Learning\n",
    "Edit the function QLearning in ./RLalgs/ql.py to implement the Q-Learning Algorithm.<br />\n",
    "<span style=\"color:red\">(10 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLalgs.ql import QLearning\n",
    "Q = QLearning(env = env.env, num_episodes = 10000, gamma = 1, lr = 0.1, e = 0.1)\n",
    "print('Action values:')\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you should get non-zero action values on non-terminal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the following to evaluate your result, comment them when you generate the pdf 0 3 3 3 0 0 0 0 3 1 0 0 0 2 1 0\n",
    "#policy_estimate = action_selection(Q)\n",
    "#render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 SARSA\n",
    "Edit the function SARSA in ./RLalgs/sarsa.py to implement the SARSA Algorithm.<br />\n",
    "<span style=\"color:red\">(10 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLalgs.sarsa import SARSA\n",
    "Q = SARSA(env = env.env, num_episodes = 9000, gamma = 1, lr = 0.1, e = 0.1)\n",
    "print('Action values:')\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you should get non-zero action values on non-terminal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the following to evaluate your result, comment them when you generate the pdf\n",
    "#policy_estimate = action_selection(Q)\n",
    "#render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Human\n",
    "You can play this game if you are interested. See if you can get the frisbee either with or without the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLalgs.utils import human_play\n",
    "#Uncomment and run the following to play the game, comment it when you generate the pdf\n",
    "#human_play(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploration VS. Exploitation\n",
    "Try to reproduce Figure 2.2 (the upper one is enough) of the Sutton's book based on the experiment described in Chapter 2.3.<br />\n",
    "<span style=\"color:red\">Extra credit (3 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the experiment and record average reward acquired in each time step\n",
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eps=[0,0.1,0.01] \n",
    "\n",
    "\n",
    "\n",
    "def epsilon_greedy(value, e):\n",
    "    \n",
    "        if random.random()<e : \n",
    "                action=np.random.randint(10)\n",
    "        else : \n",
    "                action=np.argmax(value)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "q_t=np.random.normal(0,1,(2000,10)) \n",
    "\n",
    "for e in range(len(eps)) : \n",
    "    reward_per_episode=[]\n",
    "    q_values=np.zeros((2000,10)) \n",
    "    times_chosen=np.ones((2000,10))\n",
    "     \n",
    "    reward_per_episode.append(0)\n",
    "    q_start=np.random.normal(q_t,1)\n",
    "    reward_per_episode.append(np.mean(q_start))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in tqdm(range(1,1000)) :  \n",
    "        rewards=[]\n",
    "        \n",
    "        for i in range(2000) :\n",
    "            a=epsilon_greedy(q_values[i],eps[e])\n",
    "            reward=np.random.normal(q_t[i][a],1)\n",
    "            rewards.append(reward)\n",
    "            times_chosen[i][a]=times_chosen[i][a]+1\n",
    "            q_values[i][a]=q_values[i][a]+(reward-q_values[i][a])/times_chosen[i][a]\n",
    "\n",
    "        avg=np.mean(rewards)\n",
    "        reward_per_episode.append(avg)\n",
    "    plt.plot(reward_per_episode)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('Average reward')\n",
    "    plt.legend(['eps=0','eps=0.1','eps=0.01'])\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get curves similar to that in the book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
